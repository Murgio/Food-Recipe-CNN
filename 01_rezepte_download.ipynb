{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Chefkoch.de](http://www.chefkoch.de/)\n",
    "------\n",
    "\n",
    "## Ziel: \n",
    "### Scraping der Hauptrezeptesammlung von über 300'000 verschiedenen Rezepten (1.Teil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from time import sleep, time\n",
    "from random import randint, choice\n",
    "import requests\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daten wie Rezeptname, Bewertung, Datum vom Upload des Rezeptes, etc. werden in eine csv Datei gespeichert.\n",
    "Falls das Rezept ein Bild hat, wird das Thumbnail im Ordner **search_thumbnails** abgelegt.\n",
    "\n",
    "配方名称、评分、配方上传日期等数据保存在 csv 文件中。如果菜谱有图像，则缩略图将放在 search_thumbnails 文件夹中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS\n",
    "NOW           = dt.datetime.now()\n",
    "FILE_NAME     = 'chefkoch_rezepte_' + NOW.strftime('%d-%m-%Y') + '.csv'\n",
    "DATASET_FOLDER = 'input/csv_files/'\n",
    "IMGS_FOLDER  = 'input/images/search_thumbnails/'\n",
    "\n",
    "# Chefkoch.de Seite\n",
    "CHEFKOCH_URL  = 'http://www.chefkoch.de'\n",
    "START_URL     = 'http://www.chefkoch.de/rs/s'\n",
    "CATEGORY      = '/Rezepte.html'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alle 300k Rezepte sortiert nach Datum: http://www.chefkoch.de/rs/s30o3/Rezepte.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn man Website Scrapping durchführt, ist es wichtig die robots.txt Datei zu respektieren. Manche Administratoren möchten nicht das bestimmte Directories von Bots besucht werden. https://www.chefkoch.de/robots.txt liefert:\n",
    "\n",
    "- User-agent: *  # directed to all spiders, not just Scooter\n",
    "- Disallow: /cgi-bin\n",
    "- Disallow: /stats\n",
    "- Disallow: /pictures/fotoalben/\n",
    "- Disallow: /forumuploads/\n",
    "- Disallow: /pictures/user/\n",
    "- Disallow: /user/\n",
    "- Disallow: /avatar/\n",
    "- Disallow: /cms/\n",
    "- Disallow: /produkte/\n",
    "- Disallow: /how2videos/\n",
    "\n",
    "Aufgeführt sind Directories die uns gar nicht interessieren, weshalb man getrost weiter machen kann. Nichtsdestotrotz  sind Massnahmen, wie zufällige Headers und genügend grosse Pausen zwischen den einzelnen Requests empfehlenswert, um einen möglichen Ban der Website zu vermeiden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "desktop_agents = ['Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1) AppleWebKit/602.2.14 (KHTML, like Gecko) Version/10.0.1 Safari/602.2.14',\n",
    "                 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.98 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.98 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36',\n",
    "                 'Mozilla/5.0 (Windows NT 10.0; WOW64; rv:50.0) Gecko/20100101 Firefox/50.0']\n",
    "\n",
    "def random_headers():\n",
    "    return {'User-Agent': choice(desktop_agents),'Accept':'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages:  10560\n"
     ]
    }
   ],
   "source": [
    "# Chefkoch.de Website\n",
    "CHEFKOCH_URL  = 'http://www.chefkoch.de'\n",
    "START_URL     = 'http://www.chefkoch.de/rs/s'\n",
    "CATEGORY      = '/Rezepte.html'\n",
    "category_url = START_URL + '0o3' + CATEGORY\n",
    "\n",
    "def _get_html(url):\n",
    "    page = ''\n",
    "    while page == '':\n",
    "        try:\n",
    "            page = requests.get(url, headers=random_headers())\n",
    "        except:\n",
    "            print('Connection refused')\n",
    "            time.sleep(10)\n",
    "            continue\n",
    "    return page.text\n",
    "\n",
    "def _get_total_pages(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    total_pages = soup.find('div', class_='ck-pagination qa-pagination').find('a', class_='qa-pagination-pagelink-last').text\n",
    "    return int(total_pages)\n",
    "\n",
    "html_text_total_pages = _get_html(category_url)\n",
    "#total_pages = _get_total_pages(html_text_total_pages)\n",
    "total_pages=10560\n",
    "print('Total pages: ', total_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste von allen einzelnen Rezepteurls bei Chefkoch im folgenden Format:\n",
    "1. Seite: http&#58;//www.chefkoch.de/rs/s**0**o3/Rezepte.html\n",
    "2. Seite: http&#58;//www.chefkoch.de/rs/s**30**o3/Rezepte.html\n",
    "3. Seite: http&#58;//www.chefkoch.de/rs/s**60**o3/Rezepte.html\n",
    "4. Seite: ...\n",
    "\n",
    "Auf einer Seite erhält man 30 Rezepte. Um jede Seite aufrufen zu können, muss man nur die Zahl zwischen **s** und **o3** um 30 erhöhen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "\n",
    "for i in range(0, total_pages + 1):\n",
    "    url_to_scrap = START_URL + str(i * 30) + 'o3' + CATEGORY\n",
    "    url_list.append(url_to_scrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://www.chefkoch.de/rs/s0o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s30o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s60o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s90o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s120o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s150o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s180o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s210o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s240o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s270o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s300o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s330o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s360o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s390o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s420o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s450o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s480o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s510o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s540o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s570o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s600o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s630o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s660o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s690o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s720o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s750o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s780o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s810o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s840o3/Rezepte.html',\n",
      " 'http://www.chefkoch.de/rs/s870o3/Rezepte.html']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# Die ersten 30 Seiten:\n",
    "pprint(url_list[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _write_to_recipes(data):\n",
    "    path = DATASET_FOLDER + FILE_NAME\n",
    "    with open(path, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow((data['recipe_id'],\n",
    "                        data['recipe_name'],\n",
    "                        data['average_rating'],\n",
    "                        data['stars_shown'],\n",
    "                        data['votes'],\n",
    "                        data['difficulty'],\n",
    "                        data['preparation_time'],\n",
    "                        data['date'],\n",
    "                        data['link'],\n",
    "                        data['has_picture']))\n",
    "\n",
    "def _get_picture_link(item):\n",
    "    item_class = item.find('picture').find('img').get('class')\n",
    "    if item_class == ['lazyload']:\n",
    "        img_link = item.find('picture').find('img').get('data-srcset')\n",
    "    else: \n",
    "        img_link = item.find('picture').find('source').get('srcset')\n",
    "    return(img_link)\n",
    "\n",
    "def _get_front_page(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    lis = soup.find_all('li', class_=\"search-list-item\")\n",
    "    \n",
    "    for index, li in enumerate(lis):\n",
    "\n",
    "        # get rezept ID\n",
    "        try:\n",
    "            id_r = li.get('id')\n",
    "        except:\n",
    "            id_r = ''\n",
    "\n",
    "        # bild speichern falls eins verügbar\n",
    "        try: \n",
    "            if li.find('picture') is not None:\n",
    "                img_link = _get_picture_link(li)\n",
    "                img_name = IMGS_FOLDER + str(id_r) + '.jpg'\n",
    "                urllib.request.urlretrieve(img_link, img_name)\n",
    "                has_pic = 'yes'\n",
    "            else: \n",
    "                has_pic = 'no'\n",
    "        except:\n",
    "            has_pic = ''\n",
    "\n",
    "        # link\n",
    "        try:\n",
    "            link = CHEFKOCH_URL + li.find('a').get('href')\n",
    "        except:\n",
    "            link = ''\n",
    "\n",
    "        # name des rezeptes\n",
    "        try:\n",
    "            name = li.find('div', class_='search-list-item-title').text.strip()\n",
    "        except:\n",
    "            name = ''\n",
    "\n",
    "        # durchschnitts bewertung von nutzern\n",
    "        try:\n",
    "            stars = li.find('span', class_='search-list-item-uservotes-stars').get('title')\n",
    "        except:\n",
    "            stars = ''\n",
    "\n",
    "        # anzahl sterne\n",
    "        try:\n",
    "            stars_shown = li.find('span', class_='search-list-item-uservotes-stars').get('class')[1]\n",
    "        except:\n",
    "            stars_shown = ''\n",
    "\n",
    "        # anzahl votes\n",
    "        try:\n",
    "            votes = li.find('span', class_='search-list-item-uservotes-count').text.strip()\n",
    "        except:\n",
    "            votes = ''\n",
    "\n",
    "        # schwierigkeitsgrad des rezeptes => simpel, normal oder pfiffig\n",
    "        try:\n",
    "            difficulty = li.find('span', class_='search-list-item-difficulty').text.strip()\n",
    "\n",
    "        except:\n",
    "            difficulty = ''\n",
    "\n",
    "        # zubereitungs zeit\n",
    "        try:\n",
    "            preptime = li.find('span', class_='search-list-item-preptime').text.strip()\n",
    "        except:\n",
    "            preptime = ''\n",
    "\n",
    "        # datum\n",
    "        try:\n",
    "            date = li.find('span', class_='search-list-item-activationdate').text.strip()\n",
    "        except:\n",
    "            date = ''\n",
    "\n",
    "        # write dictionary\n",
    "        data = {'recipe_id' : id_r,\n",
    "                'recipe_name' : name,\n",
    "                'average_rating': stars,\n",
    "                'stars_shown' : stars_shown,\n",
    "                'votes' : votes,\n",
    "                'difficulty' : difficulty,\n",
    "                'preparation_time' : preptime,\n",
    "                'has_picture' : has_pic,\n",
    "                'date' : date,\n",
    "                'link' : link}\n",
    "        \n",
    "        # append file\n",
    "        _write_to_recipes(data)\n",
    "        \n",
    "def scrap_main(url):\n",
    "    print('Current url: ', url)\n",
    "    html = _get_html(url)\n",
    "    _get_front_page(html)\n",
    "    #sleep(randint(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current url:  http://www.chefkoch.de/rs/s234390o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234420o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234450o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234480o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234510o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234540o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234570o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234600o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234630o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234660o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234690o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234720o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234750o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234780o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234810o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234840o3/Rezepte.html\n",
      "Current url:  http://www.chefkoch.de/rs/s234870o3/Rezepte.html\n"
     ]
    }
   ],
   "source": [
    "# start_time = time()\n",
    "# with Pool(1) as p:\n",
    "#     p.map(scrap_main, url_list[7813:])\n",
    "# print(\"--- %s seconds ---\" % (time() - start_time))\n",
    "for url in url_list[7813:7830]:\n",
    "    scrap_main(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV Datei lesen und korrigieren\n",
    "\n",
    "Unter input/csv_files/ findet man die erstellte CSV Datei.\n",
    "Grösse: 62.1 MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chefkoch_rezepte_27-12-2017.csv\r\n",
      "chefkoch_rezepte_analysis.csv\r\n",
      "chefkoch_rezepte_analysis_cleannames.csv\r\n",
      "chefkoch_rezepte_analysis_with_category.csv\r\n",
      "pic_list_27-12-2017.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls input/csv_files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'input/csv_files/chefkoch_rezepte_26-12-2017.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m chef_rezepte \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput/csv_files/chefkoch_rezepte_26-12-2017.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m chef_rezepte\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input/csv_files/chefkoch_rezepte_26-12-2017.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "chef_rezepte = pd.read_csv('input/csv_files/chefkoch_rezepte_26-12-2017.csv', header=None)\n",
    "chef_rezepte.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chef_rezepte[[8]][:10] # erste 10 zeilen der 8. spalte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beim Scraping ist ein Fehler unterlaufen. Die Links müssen als https Links und nicht als http Links gespeichert werden.\n",
    "### Korrektur:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chef_rezepte[8] = chef_rezepte[8].str.replace('http', 'https')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chef_rezepte[[8]][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chef_rezepte.columns = ['recipe_id', 'recipe_name', 'average_rating',\n",
    "                        'stars_shown', 'votes', 'difficulty', 'preparation_time',\n",
    "                        'date', 'link', 'has_picture']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chef_rezepte.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chef_rezepte.to_csv('input/csv_files/chefkoch_rezepte_27-12-2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Umbennenung der Thumbnails: Hänge ein 0 hintendran -> Thumbnail ist das erste Bild des Rezeptes.\n",
    "#### 1, 2, 3, ..., n Bilder kommen im Teil 2 dazu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'input/images/search_thumbnails/'\n",
    "files = os.listdir(path)\n",
    "i = 1\n",
    "for file in files:\n",
    "    filename, file_extension = os.path.splitext(file)\n",
    "    os.rename(os.path.join(path, file), os.path.join(path, filename + '-0' + file_extension))\n",
    "    print('renamed: ', i)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weiter gehts mit Teil 2: 02_rezepte_details.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
